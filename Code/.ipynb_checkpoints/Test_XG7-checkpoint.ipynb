{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e582d54-acb9-409f-aa46-44562ce7b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsuwal1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "New data predictions saved to predictions/new_test_predictions_with_id.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, roc_auc_score,\n",
    "    precision_recall_curve, confusion_matrix, precision_score, recall_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.validation import check_array\n",
    "import shap  # SHAP for model interpretation\n",
    "\n",
    "# Directories for output\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "os.makedirs(\"shap_outputs\", exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='logs/model_training.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Validate dataset\n",
    "def validate_data(df, required_columns):\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in dataset: {missing_columns}\")\n",
    "    if df.isnull().any().any():\n",
    "        raise ValueError(\"Dataset contains missing values.\")\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(file_path, sheet_name, target_column, id_column, date_column):\n",
    "    logging.info(\"Loading dataset...\")\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    validate_data(data, [target_column, id_column, date_column])\n",
    "    dates = data[date_column]\n",
    "    ids = data[id_column]\n",
    "    X = data.drop(columns=[date_column, id_column, target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y, dates, ids\n",
    "\n",
    "# Split and balance\n",
    "def split_and_balance_data(X, y, dates, ids, test_size=0.4, random_state=42):\n",
    "    X_train, X_test, y_train, y_test, train_dates, test_dates, train_ids, test_ids = train_test_split(\n",
    "        X, y, dates, ids, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, train_dates, test_dates, train_ids, test_ids\n",
    "\n",
    "# Train and tune\n",
    "def train_and_tune_model(X_train, y_train, param_grid, random_state=42):\n",
    "    X_train = check_array(X_train)\n",
    "    y_train = check_array(y_train, ensure_2d=False)\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        enable_categorical=False,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=StratifiedKFold(n_splits=5),\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    logging.info(\"Starting grid search for hyperparameter tuning...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logging.info(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, X_test, y_test, ids, dates, output_path):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    logging.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "    logging.info(f\"AUC-ROC: {auc:.4f}\")\n",
    "    logging.info(f\"Precision: {precision:.4f}\")\n",
    "    logging.info(f\"Recall: {recall:.4f}\")\n",
    "    logging.info(\"Classification Report:\\n\" + classification_rep)\n",
    "    logging.info(\"Confusion Matrix:\\n\" + str(conf_matrix))\n",
    "\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"ID\": ids,\n",
    "        \"Date\": dates,\n",
    "        \"True Target\": y_test,\n",
    "        \"Predicted Probability\": y_pred_proba,\n",
    "        \"Predicted Target\": y_pred\n",
    "    })\n",
    "    predictions_df.to_excel(output_path, index=False)\n",
    "    logging.info(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "# SHAP explanation\n",
    "def explain_model_with_shap(model, X_train, feature_names, output_dir=\"shap_outputs\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    logging.info(\"Starting SHAP explanation...\")\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "    # Save SHAP values to CSV\n",
    "    shap_df = pd.DataFrame(shap_values, columns=feature_names)\n",
    "    shap_df.to_csv(os.path.join(output_dir, \"shap_values.csv\"), index=False)\n",
    "    logging.info(\"SHAP values saved to shap_outputs/shap_values.csv\")\n",
    "\n",
    "    # Beeswarm plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_train_df, feature_names=feature_names, show=False)\n",
    "    plt.title(\"SHAP Beeswarm Plot: Feature Impact on Model Output\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"shap_beeswarm_plot.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logging.info(\"SHAP beeswarm plot saved to shap_outputs/shap_beeswarm_plot.png\")\n",
    "\n",
    "    # Bar plot for feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_train_df, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"SHAP Feature Importance (Mean Absolute SHAP Values)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"shap_feature_importance_bar.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logging.info(\"SHAP feature importance bar plot saved to shap_outputs/shap_feature_importance_bar.png\")\n",
    "\n",
    "    # Dependence plots for top 5 features\n",
    "    top_n = 5\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "    top_indices = np.argsort(shap_importance)[-top_n:][::-1]\n",
    "\n",
    "    for idx in top_indices:\n",
    "        feature = feature_names[idx]\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        shap.dependence_plot(\n",
    "            idx, shap_values, X_train_df, feature_names=feature_names, show=False,\n",
    "            interaction_index=\"auto\"  # Automatically select interaction feature\n",
    "        )\n",
    "        plt.title(f\"SHAP Dependence Plot: {feature}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"shap_dependence_{feature}.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f\"Dependence plot saved for {feature}\")\n",
    "\n",
    "    # Generate text summary of feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Mean_Abs_SHAP': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values(by='Mean_Abs_SHAP', ascending=False)\n",
    "    \n",
    "    summary_text = \"SHAP Feature Importance Summary:\\n\"\n",
    "    summary_text += \"Top features contributing to the model predictions:\\n\"\n",
    "    for i, row in feature_importance.head(top_n).iterrows():\n",
    "        summary_text += f\"- {row['Feature']}: Mean |SHAP| = {row['Mean_Abs_SHAP']:.4f}\\n\"\n",
    "    summary_text += \"\\nInterpretation:\\n\"\n",
    "    summary_text += \"- Features with higher mean absolute SHAP values have a greater impact on predictions.\\n\"\n",
    "    summary_text += \"- Positive SHAP values push predictions toward the positive class (1).\\n\"\n",
    "    summary_text += \"- Negative SHAP values push predictions toward the negative class (0).\\n\"\n",
    "    summary_text += \"- Beeswarm plot shows the distribution of SHAP values for each feature.\\n\"\n",
    "    summary_text += \"- Bar plot summarizes mean absolute SHAP values for feature importance.\\n\"\n",
    "    summary_text += \"- Dependence plots show how each feature's value affects predictions.\\n\"\n",
    "\n",
    "    with open(os.path.join(output_dir, \"shap_summary.txt\"), \"w\") as f:\n",
    "        f.write(summary_text)\n",
    "    logging.info(\"SHAP summary text saved to shap_outputs/shap_summary.txt\")\n",
    "\n",
    "# Test on new data\n",
    "def test_on_new_data(model, new_file_path, sheet_name, id_column, date_column, output_path):\n",
    "    logging.info(\"Loading new test data...\")\n",
    "    new_data = pd.read_excel(new_file_path, sheet_name=sheet_name)\n",
    "    validate_data(new_data, [id_column, date_column])\n",
    "    new_dates = new_data[date_column]\n",
    "    new_ids = new_data[id_column]\n",
    "    X_new = new_data.drop(columns=[date_column, id_column])\n",
    "\n",
    "    y_new_pred_proba = model.predict_proba(X_new)[:, 1]\n",
    "    y_new_pred = model.predict(X_new)\n",
    "\n",
    "    new_predictions_df = pd.DataFrame({\n",
    "        \"ID\": new_ids,\n",
    "        \"Date\": new_dates,\n",
    "        \"Predicted Probability\": y_new_pred_proba,\n",
    "        \"Predicted Target\": y_new_pred\n",
    "    })\n",
    "    new_predictions_df.to_excel(output_path, index=False)\n",
    "    logging.info(f\"New data predictions saved to {output_path}\")\n",
    "    print(f\"New data predictions saved to {output_path}\")\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        training_file_path = \"Training.xlsx\"\n",
    "        sheet_name = \"Sheet1\"\n",
    "        target_column = \"Target\"\n",
    "        id_column = \"ID\"\n",
    "        date_column = \"Date\"\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 300],\n",
    "            'learning_rate': [0.01,0.05, 0.1],\n",
    "            'max_depth': [3, 5, 6],\n",
    "            'subsample': [0.6, 0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'gamma': [0, 1, 5],\n",
    "            'min_child_weight': [1, 5, 10],\n",
    "        }\n",
    "\n",
    "        # Step 1: Load and prepare data\n",
    "        X, y, dates, ids = prepare_data(training_file_path, sheet_name, target_column, id_column, date_column)\n",
    "\n",
    "        # Step 2: Split and balance data\n",
    "        X_train, X_test, y_train, y_test, train_dates, test_dates, train_ids, test_ids = split_and_balance_data(\n",
    "            X, y, dates, ids\n",
    "        )\n",
    "\n",
    "        # Step 3: Train and tune the model\n",
    "        best_model = train_and_tune_model(X_train, y_train, param_grid)\n",
    "\n",
    "        # Step 3.5: Explain with SHAP\n",
    "        explain_model_with_shap(best_model, X_train, feature_names=X.columns.tolist())\n",
    "\n",
    "        # Step 4: Evaluate the model\n",
    "        evaluate_model(\n",
    "            best_model,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            test_ids,\n",
    "            test_dates,\n",
    "            output_path=\"predictions/testing_predictions_with_id.xlsx\"\n",
    "        )\n",
    "\n",
    "        # Step 5: Save the model\n",
    "        joblib.dump(best_model, \"models/xgboost_best_model.pkl\")\n",
    "        logging.info(\"Model training completed successfully.\")\n",
    "\n",
    "        # Step 6: Test on new data\n",
    "        test_on_new_data(\n",
    "            model=best_model,\n",
    "            new_file_path=\"Testing.xlsx\",\n",
    "            sheet_name=\"Sheet1\",\n",
    "            id_column=id_column,\n",
    "            date_column=date_column,\n",
    "            output_path=\"predictions/new_test_predictions_with_id.xlsx\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271f0ed-7180-4553-b1cc-379f4b8afd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
